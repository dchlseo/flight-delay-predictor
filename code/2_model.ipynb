{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Delay: Classification Models\n",
    "- 사용한 모델\n",
    "- 몇 번의 모델 테스트 과정에서 범주형 변수의 one-hot encoding과 label encoding의 결과 차이가 유의미하지 않았고, 숫자형 변수의 scaling 역시 불필요하다고 결론을 내려 최종 코드에서는 label encoding한 값을 사용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from joblib import dump\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, accuracy_score, precision_score, recall_score, log_loss, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Fixed Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# print('GOOGLE DRIVE MOUNT COMPLETE.')\n",
    "# !find \"/content/drive/My Drive/Colab Notebooks/data\" -name \"df_preprocessed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_Month</th>\n",
       "      <th>Estimated_Departure_Time</th>\n",
       "      <th>Estimated_Arrival_Time</th>\n",
       "      <th>Origin_Airport</th>\n",
       "      <th>Origin_Airport_ID</th>\n",
       "      <th>Origin_State</th>\n",
       "      <th>Destination_Airport</th>\n",
       "      <th>Destination_Airport_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Carrier_ID(DOT)</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>Delay</th>\n",
       "      <th>Time</th>\n",
       "      <th>concat_date</th>\n",
       "      <th>Origin_Region</th>\n",
       "      <th>Destination_Region</th>\n",
       "      <th>Season</th>\n",
       "      <th>EDT_Part_of_Day</th>\n",
       "      <th>EAT_Part_of_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000006</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>11618</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>BOS</td>\n",
       "      <td>10721</td>\n",
       "      <td>...</td>\n",
       "      <td>19977.0</td>\n",
       "      <td>N66825</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_000008</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>BWI</td>\n",
       "      <td>10821</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>CLT</td>\n",
       "      <td>11057</td>\n",
       "      <td>...</td>\n",
       "      <td>19393.0</td>\n",
       "      <td>N765SW</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>164</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_000010</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>DCA</td>\n",
       "      <td>11278</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>PIT</td>\n",
       "      <td>14122</td>\n",
       "      <td>...</td>\n",
       "      <td>20452.0</td>\n",
       "      <td>N119HQ</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>225</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_000012</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>11042</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>DEN</td>\n",
       "      <td>11292</td>\n",
       "      <td>...</td>\n",
       "      <td>19393.0</td>\n",
       "      <td>N8696E</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>Ohio_Valley</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_000013</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>615.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>MAF</td>\n",
       "      <td>13158</td>\n",
       "      <td>Texas</td>\n",
       "      <td>DEN</td>\n",
       "      <td>11292</td>\n",
       "      <td>...</td>\n",
       "      <td>20304.0</td>\n",
       "      <td>N165SY</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>262</td>\n",
       "      <td>South</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Month  Day_of_Month  Estimated_Departure_Time  \\\n",
       "0  TRAIN_000006      1            20                    1742.0   \n",
       "1  TRAIN_000008      6            13                    1420.0   \n",
       "2  TRAIN_000010      8            13                    1730.0   \n",
       "3  TRAIN_000012      1            12                    1015.0   \n",
       "4  TRAIN_000013      9            19                     615.0   \n",
       "\n",
       "   Estimated_Arrival_Time Origin_Airport  Origin_Airport_ID Origin_State  \\\n",
       "0                  1903.0            EWR              11618   New Jersey   \n",
       "1                  1550.0            BWI              10821     Maryland   \n",
       "2                  1844.0            DCA              11278     Virginia   \n",
       "3                  1145.0            CLE              11042         Ohio   \n",
       "4                   706.0            MAF              13158        Texas   \n",
       "\n",
       "  Destination_Airport  Destination_Airport_ID  ... Carrier_ID(DOT)  \\\n",
       "0                 BOS                   10721  ...         19977.0   \n",
       "1                 CLT                   11057  ...         19393.0   \n",
       "2                 PIT                   14122  ...         20452.0   \n",
       "3                 DEN                   11292  ...         19393.0   \n",
       "4                 DEN                   11292  ...         20304.0   \n",
       "\n",
       "   Tail_Number Delay  Time concat_date  Origin_Region  Destination_Region  \\\n",
       "0       N66825     0    81          20      Northeast           Northeast   \n",
       "1       N765SW     0    90         164      Northeast           Southeast   \n",
       "2       N119HQ     1    74         225      Southeast           Northeast   \n",
       "3       N8696E     0    90          12    Ohio_Valley           Southwest   \n",
       "4       N165SY     0    51         262          South           Southwest   \n",
       "\n",
       "   Season EDT_Part_of_Day EAT_Part_of_Day  \n",
       "0  Winter         Evening         Evening  \n",
       "1  Summer         Evening         Evening  \n",
       "2  Summer         Evening         Evening  \n",
       "3  Winter       Afternoon         Evening  \n",
       "4  Autumn         Morning         Morning  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../df_preprocessed.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 200121 entries, 0 to 200120\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   ID                        200121 non-null  object \n",
      " 1   Month                     200121 non-null  int64  \n",
      " 2   Day_of_Month              200121 non-null  int64  \n",
      " 3   Estimated_Departure_Time  200121 non-null  float64\n",
      " 4   Estimated_Arrival_Time    200121 non-null  float64\n",
      " 5   Origin_Airport            200121 non-null  object \n",
      " 6   Origin_Airport_ID         200121 non-null  int64  \n",
      " 7   Origin_State              200121 non-null  object \n",
      " 8   Destination_Airport       200121 non-null  object \n",
      " 9   Destination_Airport_ID    200121 non-null  int64  \n",
      " 10  Destination_State         200121 non-null  object \n",
      " 11  Distance                  200121 non-null  float64\n",
      " 12  Airline                   200121 non-null  object \n",
      " 13  Carrier_ID(DOT)           200121 non-null  float64\n",
      " 14  Tail_Number               200121 non-null  object \n",
      " 15  Delay                     200121 non-null  int64  \n",
      " 16  Time                      200121 non-null  int64  \n",
      " 17  concat_date               200121 non-null  int64  \n",
      " 18  Origin_Region             200121 non-null  object \n",
      " 19  Destination_Region        200121 non-null  object \n",
      " 20  Season                    200121 non-null  object \n",
      " 21  EDT_Part_of_Day           200121 non-null  object \n",
      " 22  EAT_Part_of_Day           200121 non-null  object \n",
      "dtypes: float64(4), int64(7), object(12)\n",
      "memory usage: 36.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delay\n",
       "0    164817\n",
       "1     35304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Delay.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Undersampling\n",
    "- 0과 1의 비율을 1:1로 과소표집함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delay\n",
       "1    35304\n",
       "0    35304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delayed_data = df[df['Delay'] == 1]\n",
    "not_delayed_data = df[df['Delay'] == 0]\n",
    "missing_data = df[df['Delay'] == 2]\n",
    "\n",
    "undersampled_not_delayed = not_delayed_data.sample(n=len(delayed_data), random_state=42)\n",
    "\n",
    "undersampled_data = pd.concat([delayed_data, undersampled_not_delayed], axis=0)\n",
    "\n",
    "undersampled_data_count = undersampled_data['Delay'].value_counts()\n",
    "\n",
    "undersampled_data_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 변수: LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL ENCODING COMPLETE.\n"
     ]
    }
   ],
   "source": [
    "categorical_features = undersampled_data.select_dtypes(exclude=['int64','int32' ,'float64']).columns.tolist()\n",
    "\n",
    "#LabelEncoder\n",
    "label_encoders = {}\n",
    "\n",
    "for i in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(undersampled_data[i])\n",
    "    undersampled_data[i]=le.transform(undersampled_data[i])\n",
    "\n",
    "    # LabelEncoder 딕셔너리에 저장\n",
    "    label_encoders[i] = le\n",
    "\n",
    "# LabelEncoder pickle 파일로 저장\n",
    "with open('label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "print('LABEL ENCODING COMPLETE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 데이터 저장\n",
    "undersampled_data.to_parquet('undersampled_data.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampled_data = pd.read_parquet('undersampled_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56486, 21), (14122, 21))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = undersampled_data.drop(['ID', 'Delay'], axis=1) # ID, Delay(=종속변수)\n",
    "y = undersampled_data[\"Delay\"]\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42, stratify=y, test_size=0.2)\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if required datasets are defined\n",
    "if 'X_rus' not in locals() or 'y_rus' not in locals() or 'test_X' not in locals() or 'test_y' not in locals():\n",
    "    raise ValueError(\"One or more of the required datasets (X_rus, y_rus, test_X, test_y) are not defined.\")\n",
    "\n",
    "# Models with adjusted hyperparameters\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=SEED)),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=SEED)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=50, random_state=SEED)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=50, random_state=SEED)),\n",
    "    ('XGBoost', xgb.XGBClassifier(random_state=SEED, verbosity=1)),\n",
    "    ('LightGBM', lgb.LGBMClassifier(random_state=SEED))\n",
    "]\n",
    "\n",
    "# Lists to store metric values for each model\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "log_losses = []\n",
    "\n",
    "# Reports & Model Training\n",
    "for name, model in models:\n",
    "    start_time = time.time()  # Start time\n",
    "    \n",
    "    model.fit(X_rus, y_rus)\n",
    "    preds = model.predict(test_X)\n",
    "    prob_preds = model.predict_proba(test_X)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(test_y, preds)\n",
    "    precision = precision_score(test_y, preds)\n",
    "    recall = recall_score(test_y, preds)\n",
    "    loss = log_loss(test_y, prob_preds)\n",
    "    \n",
    "    # Append metrics to lists\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    log_losses.append(loss)\n",
    "    \n",
    "    end_time = time.time()  # End time\n",
    "    \n",
    "    # Print model results in a formatted manner\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Training & Evaluation Time: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Log Loss: {loss:.4f}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Cross-validation with parallelization\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'neg_log_loss']\n",
    "    cv_scores = cross_validate(model, X_rus, y_rus, cv=5, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    print(\"\\nCross-Validation Scores:\")\n",
    "    for metric, scores in cv_scores.items():\n",
    "        if metric == \"test_neg_log_loss\":\n",
    "            mean_score = -scores.mean()\n",
    "            std_score = scores.std()\n",
    "            print(f\"{metric}: {mean_score:.4f} (+/- {std_score * 2:.4f})\")\n",
    "        else:\n",
    "            print(f\"{metric}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_y, preds))\n",
    "    print(\"=\" * 60)  # Separate each model's results for clarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오늘 날짜 가져오기: MM-DD\n",
    "current_date = datetime.now().strftime(\"%m-%d\")\n",
    "\n",
    "for name, model in models:\n",
    "    \n",
    "    # 생성된 모델 저장\n",
    "    filename = f'{name.replace(\" \", \"_\")}_{current_date}_model.joblib'\n",
    "    \n",
    "    dump(model, filename)  # Save the model to the specified filename\n",
    "    \n",
    "    print(f\"Model '{name}' saved as {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Logistic Regression', 'Decision Tree', 'Random Forest', \n",
    "               'Gradient Boosting', 'XGBoost', 'LightGBM']\n",
    "\n",
    "# 모델 학습 결과 시각화\n",
    "metrics = [accuracies, precisions, recalls, log_losses]\n",
    "titles = ['Model Accuracy', 'Model Precision', 'Model Recall', 'Model Log Loss']\n",
    "ylabels = ['Accuracy', 'Precision', 'Recall', 'Log Loss']\n",
    "ylims = [(0.5, 1), (0.5, 1), (0.5, 1), (0, 1)]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.bar(model_names, metrics[i], color=['blue', 'green', 'red', 'cyan', 'purple', 'orange'])\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_ylabel(ylabels[i])\n",
    "    ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    ax.set_ylim(ylims[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
